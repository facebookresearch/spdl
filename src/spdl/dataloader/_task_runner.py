import asyncio
import logging
from queue import Queue
from threading import BoundedSemaphore, Event, Thread
from typing import Any, AsyncIterable, Awaitable, Callable, Iterable, TypeVar

_LG = logging.getLogger(__name__)

__all__ = [
    "BackgroundTaskProcessor",
    "apply_async",
]

T = TypeVar("T")


################################################################################
# Impl for AsyncTaskRunner
################################################################################
def _run_async_gen(aiterable, sentinel, queue, stop_request):
    async def _generator_loop():
        async for item in aiterable:
            queue.put(item)

            if stop_request.is_set():
                _LG.debug("Stop requested.")
                break
        queue.put(sentinel)
        _LG.debug("exiting _generator_loop.")

    asyncio.set_event_loop(asyncio.new_event_loop())
    asyncio.run(_generator_loop())


def _buffer(generator, max_concurrency=10):
    semaphore = BoundedSemaphore(max_concurrency)

    def _cb(_):
        semaphore.release()

    futs = []
    for future in generator:
        semaphore.acquire()
        future.add_done_callback(_cb)
        futs.append(future)

        while len(futs) > 0 and futs[0].done():
            yield futs.pop(0)

    yield from futs


def _run_gen(generator, sentinel, queue, stop_request):
    for future in _buffer(generator):
        try:
            item = future.result()
        except Exception as e:
            _LG.error("%s", e)
        else:
            queue.put(item)

        if stop_request.is_set():
            _LG.debug("Stop requested.")
            generator.close()
            break
        _LG.debug("exiting _generator_loop.")

    queue.put(sentinel)


class BackgroundTaskProcessor:
    """Run generator in background and iterate the items.

    Args:
        iterable: Generator to run in the background.

        max_queue_size: The size of the queue that is used to pass the
            generated items from the background thread to the main thread.
            If the queue is full, the background thread will be blocked.
    """

    def __init__(self, iterable: AsyncIterable[Any], max_queue_size: int = 10):
        self._queue = Queue(maxsize=max_queue_size)

        self._sentinel = object()
        self._stop_request = Event()
        self._thread = Thread(
            target=(_run_async_gen if hasattr(iterable, "__aiter__") else _run_gen),
            args=(iterable, self._sentinel, self._queue, self._stop_request),
        )

    def start(self):
        """Start the background job that runs the given async generator."""
        self._thread.start()

    def __iter__(self):
        """Iterate over the items generated by the async generator."""
        while (item := self._queue.get()) is not self._sentinel:
            yield item

    def request_stop(self):
        """Request to stop the background thread.

        This is the best-effort stop request.
        The background thread will not stop unitl it finishes processing the
        current item.
        """
        _LG.info("Stopping the background task runner.")
        self._stop_request.set()
        self._flush()

    def _flush(self):
        _LG.debug("Flushing the queue.")
        while (_ := self._queue.get()) is not self._sentinel:
            pass
        _LG.debug("Flushing the queue. - done")

    def join(self):
        """Wait for the background thread to join."""
        _LG.info("Waiting for the background task runner thread to join.")
        self._thread.join()


################################################################################
# Impl for apply_async
################################################################################
def _check_exception(task, stacklevel=1):
    try:
        task.exception()
    except asyncio.exceptions.CancelledError:
        _LG.warning("Task [%s] was cancelled.", task.get_name(), stacklevel=stacklevel)
    except Exception as err:
        _LG.error("Task [%s] failed: %s", task.get_name(), err, stacklevel=stacklevel)


async def _apply_async(async_func, generator, max_concurrency):
    semaphore = asyncio.BoundedSemaphore(max_concurrency)

    def _cb(task):
        semaphore.release()
        _check_exception(task, stacklevel=2)

    tasks = set()
    for i, item in enumerate(generator):
        await semaphore.acquire()
        task = asyncio.create_task(async_func(item), name=f"item_{i}")
        task.add_done_callback(_cb)
        tasks.add(task)

        # Occasionally remove the done tasks.
        if len(tasks) >= 1000:
            _, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)

    if tasks:
        await asyncio.wait(tasks)

    _LG.debug("_apply_async - done")


async def apply_async(
    async_func: Callable[[T], Awaitable[Any]],
    generator: Iterable[T],
    max_concurrency: int = 10,
):
    """Apply async function to the non-async generator.

    This function iterates the items in the generator, and apply async function,
    buffer the coroutines so that at any time, there are `max_concurrency`
    coroutines running. Each coroutines put the resulting items to the internal
    queue as soon as it's ready.

    !!! note

        The order of the output may not be the same as generator.

    Args:
        async_func: The async function to apply.
        generator: The generator to apply the async function to.
        max_concurrency: The maximum number of concurrent async tasks.

    Yields:
        The output of the async function.
    """
    # Implementation Note:
    #
    # The simplest form to apply the async function to the generator is
    #
    # ```
    # for item in generator:
    #     yield await async_func(item)
    # ```
    #
    # But this applies the function sequentially, so it is not efficient.
    #
    # We need to run multiple coroutines in parallel, and fetch the results.
    # But since the size of the generator is not know, and it can be as large
    # as millions, we need to set the max buffer size.
    #
    # A common approach is to put tasks in `set` and use `asyncio.wait`.
    # But this approach leaves some ambiguity as "when to wait"?
    #
    # ```
    # tasks = set()
    # for item in generator:
    #     task = asyncio.create_task(async_func(item))
    #     tasks.add(task)
    #
    #     if <SOME_OCCASION>:  # When is optimal?
    #         done, tasks = await asyncio.wait(
    #             tasks, return_when=asyncio.FIRST_COMPLETED)
    #         for task in done:
    #             yield task.result()
    # ```
    #
    # This kind of parameter has non-negligible impact on the performance, and
    # usually the best performance is achieved when there is no such parameter,
    # so that the async loop does the job for us.
    #
    # To eliminate such parameter, we use asyncio.Queue object and pass the results
    # into this queue, as soon as it's ready. We only await the `Queue.get()`. Then,
    # yield the results fetched from the queue.
    queue = asyncio.Queue()

    # We use sentinel to detect the end of the background job
    sentinel = object()

    def _g():
        yield from generator
        yield sentinel

    async def _f(v):
        await queue.put(sentinel if v is sentinel else await async_func(v))

    coro = _apply_async(_f, _g(), max_concurrency)
    task = asyncio.create_task(coro, name="_apply_async")
    task.add_done_callback(_check_exception)

    while (item := await queue.get()) is not sentinel:
        yield item

    await task
