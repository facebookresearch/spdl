import asyncio
import logging
from concurrent.futures import Future
from queue import Queue
from threading import BoundedSemaphore, Event, Thread
from typing import Any, AsyncIterable, Awaitable, Callable, Iterable, TypeVar

import spdl.utils

_LG = logging.getLogger(__name__)

__all__ = [
    "BackgroundTaskProcessor",
    "apply_async",
    "apply_concurrent",
]

T = TypeVar("T")


################################################################################
# Impl for AsyncTaskRunner
################################################################################
def _run_async_gen(aiterable, sentinel, queue, stopped):
    async def _generator_loop():
        try:
            async for item in aiterable:
                queue.put(item)

                if stopped.is_set():
                    _LG.debug("Stop requested.")
                    break
        finally:
            queue.put(sentinel)
            stopped.set()
        _LG.debug("exiting _generator_loop.")

    asyncio.set_event_loop(asyncio.new_event_loop())
    asyncio.run(_generator_loop())


def _run_gen(generator, sentinel, queue, stopped):
    try:
        for future in generator:
            try:
                item = future.result()
            except Exception as e:
                _LG.error("%s", e)
            else:
                queue.put(item)

            if stopped.is_set():
                _LG.debug("Stop requested.")
                generator.close()
                break
            _LG.debug("exiting _generator_loop.")
    finally:
        queue.put(sentinel)
        stopped.set()


class _TaskIterator:
    def __init__(self, queue, sentinel):
        self._queue = queue
        self._sentinel = sentinel

    def __iter__(self):
        """Iterate over the items generated by the async generator."""
        while (item := self._queue.get()) is not self._sentinel:
            yield item


class BackgroundTaskProcessor:
    """Run generator in background and iterate the items.

    Args:
        iterable: Generator to run in the background. It can be an
            asynchronou generator or a regular generator.

        max_queue_size: The size of the queue that is used to pass the
            generated items from the background thread to the main thread.
            If the queue is full, the background thread will be blocked.


    ??? example
        ```python
        async def generator():
            for i in range(10):
                yield i

        with BackgroundTaskProcessor(generator) as it:
            for item in it:
                # Do something with the item.
        ```
    """

    def __init__(self, iterable: AsyncIterable[Any], max_queue_size: int = 10):
        self._queue = Queue(maxsize=max_queue_size)
        # Used to indicate the end of the queue.
        self._sentinel = object()

        # Used to flag cancellation from outside and to flag the completion from the inside.
        self._stopped = Event()
        self._thread = Thread(
            target=(_run_async_gen if hasattr(iterable, "__aiter__") else _run_gen),
            args=(iterable, self._sentinel, self._queue, self._stopped),
        )

    def __enter__(self):
        self._thread.start()
        return _TaskIterator(self._queue, self._sentinel)

    def __exit__(self, exc_type, exc_value, traceback):
        # If _stopped is set, the background thread is completed.
        # No more items are generated, and the sentinel value might have consumed
        # by _TaskIterator. We cannot flush the queue.
        # If _stopped is not set, the background thread is still running,
        # but the _TaskIterator might have been deleted, which means no one is consuming
        # the queue, and the queue might get clogged, and the background thread gets blocked.
        # In this case, we flush the queue.
        if not self._stopped.is_set():
            _LG.info("Stopping the background task runner.")
            self._stopped.set()
            self._flush()

        _LG.info("Waiting for the background task runner thread to join.")
        self._thread.join()

    def _flush(self):
        _LG.debug("Flushing the queue.")
        while (_ := self._queue.get()) is not self._sentinel:
            pass


################################################################################
# Impl for apply_concurrent
################################################################################
def _apply_concurrent(generator, max_concurrency=10):
    semaphore = BoundedSemaphore(max_concurrency)

    def _cb(_):
        semaphore.release()

    futs = []
    try:
        for future in generator:
            semaphore.acquire()
            future.add_done_callback(_cb)
            futs.append(future)

            while len(futs) > 0 and futs[0].done():
                yield futs.pop(0)

        yield from futs
    except GeneratorExit:
        _LG.info("Generator exited - waiting for the ongoing futures to complete.")
        spdl.utils.wait_futures(futs).result()
        raise


def apply_concurrent(
    func: Callable[[T], Future[Any]],
    generator: Iterable[T],
    max_concurrency: int = 10,
):
    def gen():
        for item in generator:
            yield func(item)

    yield from _apply_concurrent(gen(), max_concurrency)


################################################################################
# Impl for apply_async
################################################################################
def _check_exception(task, stacklevel=1):
    try:
        task.result()
    except asyncio.exceptions.CancelledError:
        _LG.warning("Task [%s] was cancelled.", task.get_name(), stacklevel=stacklevel)
    except Exception as err:
        _LG.error("Task [%s] failed: %s", task.get_name(), err, stacklevel=stacklevel)


async def _apply_async(async_func, generator, queue, sentinel, max_concurrency):
    semaphore = asyncio.BoundedSemaphore(max_concurrency)

    async def _f(item):
        async with semaphore:
            result = await async_func(item)
            await queue.put(result)

    tasks = set()
    for i, item in enumerate(generator):
        task = asyncio.create_task(_f(item), name=f"item_{i}")
        task.add_done_callback(lambda t: _check_exception(t, stacklevel=2))
        tasks.add(task)

        # Occasionally remove the done tasks.
        if len(tasks) >= 3 * max_concurrency:
            _, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)

    if tasks:
        await asyncio.wait(tasks)

    _LG.debug("_apply_async - done")
    await queue.put(sentinel)


async def apply_async(
    async_func: Callable[[T], Awaitable[Any]],
    generator: Iterable[T],
    max_concurrency: int = 10,
    timeout: float = 300,
):
    """Apply async function to the non-async generator.

    This function iterates the items in the generator, and apply async function,
    buffer the coroutines so that at any time, there are `max_concurrency`
    coroutines running. Each coroutines put the resulting items to the internal
    queue as soon as it's ready.

    !!! note

        The order of the output may not be the same as generator.

    Args:
        async_func: The async function to apply.
        generator: The generator to apply the async function to.
        max_concurrency: The maximum number of concurrent async tasks.
        timeout: The maximum time to wait for the async function. (Unit: second)

    Yields:
        The output of the async function.
    """
    # Implementation Note:
    #
    # The simplest form to apply the async function to the generator is
    #
    # ```
    # for item in generator:
    #     yield await async_func(item)
    # ```
    #
    # But this applies the function sequentially, so it is not efficient.
    #
    # We need to run multiple coroutines in parallel, and fetch the results.
    # But since the size of the generator is not know, and it can be as large
    # as millions, we need to set the max buffer size.
    #
    # A common approach is to put tasks in `set` and use `asyncio.wait`.
    # But this approach leaves some ambiguity as "when to wait"?
    #
    # ```
    # tasks = set()
    # for item in generator:
    #     task = asyncio.create_task(async_func(item))
    #     tasks.add(task)
    #
    #     if <SOME_OCCASION>:  # When is optimal?
    #         done, tasks = await asyncio.wait(
    #             tasks, return_when=asyncio.FIRST_COMPLETED)
    #         for task in done:
    #             yield task.result()
    # ```
    #
    # This kind of parameter has non-negligible impact on the performance, and
    # usually the best performance is achieved when there is no such parameter,
    # so that the async loop does the job for us.
    #
    # To eliminate such parameter, we use asyncio.Queue object and pass the results
    # into this queue, as soon as it's ready. We only await the `Queue.get()`. Then,
    # yield the results fetched from the queue.
    queue = asyncio.Queue()

    # We use sentinel to detect the end of the background job
    sentinel = object()

    coro = _apply_async(async_func, generator, queue, sentinel, max_concurrency)
    task = asyncio.create_task(coro, name="_apply_async")
    task.add_done_callback(_check_exception)

    while True:
        item = await asyncio.wait_for(queue.get(), timeout)
        if item is sentinel:
            break
        yield item

    await task
