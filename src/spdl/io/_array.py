# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

__all__ = [
    "load_npy",
]
import ast
import struct
from dataclasses import dataclass
from typing import Any

import numpy as np
from numpy.lib.format import MAGIC_LEN, MAGIC_PREFIX
from numpy.typing import NDArray

# pyre-strict


@dataclass
class _ArrayInterface:
    shape: tuple[int, ...]  # pyre-ignore: [35]
    typestr: str  # pyre-ignore: [35]
    data: memoryview  # pyre-ignore: [35]
    offset: int = 0  # pyre-ignore: [35]
    version: int = 3  # pyre-ignore: [35]

    @property
    def __array_interface__(self) -> dict[str, Any]:
        return {
            "shape": self.shape,
            "typestr": self.typestr,
            "data": self.data,
            "offset": self.offset,
            "version": self.version,
        }


def _get_header_size_info(version: tuple[int, int]) -> tuple[str, str]:
    match version:
        case (1, 0):
            return ("<H", "latin1")
        case (2, 0):
            return ("<I", "latin1")
        case (3, 0):
            return ("<I", "utf8")
        case _:
            raise ValueError(f"Unexpected version {version}.")


def load_npy(data: bytes | bytearray, *, copy: bool = False) -> NDArray:
    """Load NumPy NDArray from bytes.

    This function loads NumPy NDArray from memory. It is equivalent to
    ``numpy.load(io.BytesIO(data))``, but it is more efficient.

    .. note::

       This function does not support ``object`` dtype, and Fortran order.

    Example:

        >>> ref = np.arange(20)
        >>> buffer = BytesIO()
        >>> np.save(buffer, ref)
        >>> buffer.seek(0)
        >>> data = buffer.getvalue()
        >>> restore = spdl.io.load_npy(data)
        >>> assert np.array_equal(restore, ref)

    Args:
        data: The data generated by :py:func:`numpy.save` function.
            (Note that it is different from :py:meth:`numpy.ndarray.tobytes`,
            which does not contain shape and dtype.)
        copy: Whether to copy data. Default: no copy.

    Returns:
        The restored array data.

    .. seealso::

       - :py:mod:`numpy.lib.format`: The detail of NPY serialization is found.

       - `_read_array_header <https://github.com/numpy/numpy/blob/v2.2.0/numpy/lib/format.py#L604>`_:
         The function called by :py:func:`numpy.load` to parse the header.
       - `_read_array <https://github.com/numpy/numpy/blob/v2.2.0/numpy/lib/format.py#L762>`_:
         The function called by :py:func:`numpy.load` when loading the data region of NPY file.

    .. note::

       There is a branch in
       `_read_array <https://github.com/numpy/numpy/blob/v2.2.0/numpy/lib/format.py#L827-L854>`_
       function where the execution can call some faster implementation.
       Howver, :py:class:`~io.BytesIO` does not meet the condition.
       (:py:func:`~numpy.lib.format.isfileobj` function returns ``False`` for :py:class:`io.BytesIO`.
       [`source <https://github.com/numpy/numpy/blob/v2.2.0/numpy/lib/format.py#L999>`_])
       Even if the execution takes the faster :py:func:`numpy.fromfile` path, it
       `creates a new array <https://github.com/numpy/numpy/blob/v2.2.0/numpy/_core/records.py#L935-L939>`_.

    """
    if len(data) < MAGIC_LEN:
        raise ValueError("The input data is too short.")

    magic_str = data[:MAGIC_LEN]
    if not magic_str.startswith(MAGIC_PREFIX):
        raise ValueError(rf"Expected the data to start with {MAGIC_PREFIX}.")

    major, minor = magic_str[-2:]
    hlength_type, encoding = _get_header_size_info((major, minor))

    info_length_size = struct.calcsize(hlength_type)
    info_start = MAGIC_LEN + info_length_size

    if len(data) < info_start:
        raise ValueError("Failed to parse info. The input data is invalid.")
    info_length_str = data[MAGIC_LEN:info_start]
    info_length = struct.unpack(hlength_type, info_length_str)[0]

    data_start = info_start + info_length
    if len(data) < data_start:
        raise ValueError(
            "Failed to parse data. The recorded data size exceeds the provided data size."
        )
    info_str = data[info_start:data_start]

    info = ast.literal_eval(info_str.decode(encoding))

    if info.get("fortran_order"):
        raise ValueError(
            "Array saved with `format_order=True is not supported. Please use `numpy.load`."
        )

    # TODO: Try `numpy.frombuffer``
    # https://github.com/numpy/numpy/blob/e20317a43d3714f9085ad959f68c1ba6bc998fcd/numpy/_core/src/multiarray/ctors.c#L3711
    aif = _ArrayInterface(
        shape=info["shape"],
        typestr=info["descr"],
        data=memoryview(data),
        offset=data_start,
        version=2,
    )

    return np.array(aif, copy=copy)
